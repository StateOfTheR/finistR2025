[
  {
    "objectID": "instructions.html",
    "href": "instructions.html",
    "title": "Instructions pour le dépot sur le site web",
    "section": "",
    "text": "Protocole https :\ngit clone https://github.com/StateOfTheR/finistR2025.git\nAvec clés SSH : git clone git@github.com:git@github.com:StateOfTheR/finistR2025.git\n\n\nLien vers une doc complète."
  },
  {
    "objectID": "instructions.html#cloner-le-dépôt-git-du-bootcamp",
    "href": "instructions.html#cloner-le-dépôt-git-du-bootcamp",
    "title": "Instructions pour le dépot sur le site web",
    "section": "",
    "text": "Protocole https :\ngit clone https://github.com/StateOfTheR/finistR2025.git\nAvec clés SSH : git clone git@github.com:git@github.com:StateOfTheR/finistR2025.git\n\n\nLien vers une doc complète."
  },
  {
    "objectID": "instructions.html#processus-de-mise-en-commun-des-ateliers",
    "href": "instructions.html#processus-de-mise-en-commun-des-ateliers",
    "title": "Instructions pour le dépot sur le site web",
    "section": "Processus de mise en commun des ateliers",
    "text": "Processus de mise en commun des ateliers\n\nCréer une branche propre à l’atelier nommée explicitement mon_nom_parlant et basculer dessus\n\ngit checkout -b mon_nom_parlant\n\nCréer un fichier Rmarkdown de restitution de votre atelier fichier.Rmd dans votre branche\n\ngit add fichier.Rmd\ngit commit -m \"restitution atelier\"\n\nPousser vos modifications sur le serveur distant\n\ngit  push --set-upstream origin mon_nom_parlant ou\ngit  push\n\nFaire une pull request (PR) sur github\nindiquer dans le message de la PR la liste des packages ou autres besoins\nQuand la PR passe les tests, demander le merge.\ncorriger les erreurs éventuelles dans la compilation du Rmarkdown\nles admins peuvent avoir à mettre à jour l’image docker"
  },
  {
    "objectID": "instructions.html#détails-du-fonctionnement",
    "href": "instructions.html#détails-du-fonctionnement",
    "title": "Instructions pour le dépot sur le site web",
    "section": "Détails du fonctionnement",
    "text": "Détails du fonctionnement\n\nLe docker\nLien vers la fiche pense-bête\nVers d’autres ressources utiles\nPour créer des images Docker en local sur sa machine, voici une liste de commandes utiles\n\nPour construire une image docker, il faut créer un fichier Dockerfile qui contient la recette du Docker. Pour ce site le ficher Dockerfile a la forme suivante\n\npuis demander la construction de l’image à l’aide de la commande\n\n docker build -t nom_depot_dockerhub/nom_du_repo:version  . ## avec un nom\n\net enfin pousser sur Dockerhub\n\n docker push nom_depot_dockerhub/nom_du_repo:version\n\n\n\nLes actions\nDans les action de Github, on peut spécifier un container docker à utiliser, c’est ce que fait la ligne container du fichier d’action suivant, utiliser pour créer ce site web"
  },
  {
    "objectID": "sparse_cholesky.html",
    "href": "sparse_cholesky.html",
    "title": "Tutoriel sur la factorisation de Cholesky avec des matrices creuses",
    "section": "",
    "text": "Note\n\n\n\nL’objectif de ce tutoriel est d’appréhender (douloureusement) la factorisation de Cholesky pour des matrices sparses. Il s’inspire fortement de plusieurs ressources:\n\n2 posts de blog de Dan Simpson post 1 et post 2\n1 cours [C1] de Michael T Heath et Edgar Solomonik sur les systèmes linéaires sparses\n1 cours [C2] de Grégoire Pichon sur les arbres d’élimination"
  },
  {
    "objectID": "sparse_cholesky.html#équations-de-récursion",
    "href": "sparse_cholesky.html#équations-de-récursion",
    "title": "Tutoriel sur la factorisation de Cholesky avec des matrices creuses",
    "section": "Équations de récursion",
    "text": "Équations de récursion\nLe calcul de L (une fois son support connu) se fait via les équations de récursions suivantes données ici pour la colonne \\(j=5\\) et utilisant le fait que si \\(L_{ji} = 0\\), la colonne \\(i\\) n’est pas utilisée pour la mise à jour de \\(j\\).\n\nInitialisation \\[\n\\begin{pmatrix}\nt_{1}\\\\\n0\\\\\nt_{2}\\\\\nt_{3}\\\\\nt_{4}\\\\\n\\end{pmatrix} =\n\\begin{pmatrix}\na_{55}\\\\\n0\\\\\n0\\\\\n0\\\\\na_{95}\\\\\n\\end{pmatrix}\n\\]\nMise à jour \\[\n\\begin{pmatrix}\nt_{1}\\\\\n0\\\\\nt_{2}\\\\\nt_{3}\\\\\nt_{4}\\\\\n\\end{pmatrix} =\n\\begin{pmatrix}\nt_{1}\\\\\n0\\\\\nt_{2}\\\\\nt_{3}\\\\\nt_{4}\\\\\n\\end{pmatrix} - l_{51} . \\begin{pmatrix}\nl_{51}\\\\\n0\\\\\nl_{71}\\\\\n0\\\\\n0\\\\\n\\end{pmatrix} - l_{52} . \\begin{pmatrix}\nl_{52}\\\\\n0\\\\\n0\\\\\nl_{82}\\\\\n0\\\\\n\\end{pmatrix}\n\\]\nCalcul dans \\(L\\) \\[\n\\begin{pmatrix}\nl_{51}\\\\\n0\\\\\nl_{52}\\\\\nl_{53}\\\\\nl_{54}\\\\\n\\end{pmatrix} = \\frac{1}{\\sqrt{t_{1}}} .\n\\begin{pmatrix}\nt_{1}\\\\\n0\\\\\nt_{2}\\\\\nt_{3}\\\\\nt_{4}\\\\\n\\end{pmatrix}\n\\]\n\n\n\n\n\n\n\nAvertissement\n\n\n\nLes représentations CSC utilisées jusqu’à présent pour calculer le support de \\(L\\) (à savoir L_indices et L_indptr) utilisait l’expression de \\(A\\) sous forme symmétrique. La représentation CSC de \\(L\\) est la même suivant qu’on utilise \\(L\\) ou sa partie triangulaire inférieure (puisque \\(L\\) est par construction triangulaire inférieure). Pour initialiser \\(L_x\\), on a donc besoin de partir de la représentation CSC triangulaire inférieure de \\(A\\) uniquement.\n\n\nComme \\(L\\) et \\(A\\) n’ont pas le même support (L_x est plus long que A_x), il faut attention au moment d’initialiser \\(L\\) à partir de \\(A\\) _deep_copy_csc permet d’initialiser L_x avec la bonne longeur et les valeurs de A_x placées au bon endroit.\n\ndef _deep_copy_csc(A_indices, A_indptr, A_x, L_indices, L_indptr):\n  n = len(A_indptr) - 1\n  L_x = np.zeros(len(L_indices))\n  \n  for j in range(0, n):\n    copy_idx = np.nonzero(np.isin(L_indices[L_indptr[j]:L_indptr[j + 1]],\n                                  A_indices[A_indptr[j]:A_indptr[j+1]]))[0]\n    L_x[L_indptr[j] + copy_idx] = A_x[A_indptr[j]:A_indptr[j+1]]\n  return L_x\n\n\nA_tril = np.tril(A)\nA_tril_csc = sparse.CSC.fromdense(A_tril)\nL_x = _deep_copy_csc(A_tril_csc.indices, A_tril_csc.indptr, A_tril_csc.data, L_indices, L_indptr) # il faut initialiser L_x avec la bonne longeur mais aussi les valeurs de A placées au bon endroit\n# c'est le rôle de deep_copy_csc\nprint(L_x)\n\n[9. 1. 1. 9. 1. 1. 9. 1. 1. 9. 1. 1. 9. 0. 0. 1. 9. 0. 0. 1. 9. 0. 1. 9.\n 1. 9.]\n\n\n\n\n\n\n\n\nNote\n\n\n\nOn constate bien que _deep_copy_csc a recopié les valeurs de A_x dans L_x mais en y ajoutant des \\(0\\).\n\n\n\n\n\n\n\n\nAu sujet de JIT\n\n\n\nOn souhaite ne pas construire la liste descendant à chaque fois, ce qu’on veux jitter c’est cette dernière fonction: à structure donnée on veut calculer les valeurs de L. L_indices et L_indptr ne changent pas ! On va essayer de modifier l’algorithme d’élimination tree pour quelle retourne la liste des descendants."
  },
  {
    "objectID": "sparse_cholesky.html#calcul-effectif-de-l_x",
    "href": "sparse_cholesky.html#calcul-effectif-de-l_x",
    "title": "Tutoriel sur la factorisation de Cholesky avec des matrices creuses",
    "section": "Calcul effectif de L_x",
    "text": "Calcul effectif de L_x\nLa fonction reprend celle décrite dans post 1 mais met à profit la représentation CSR (row_useful) précédemment calculée pour ne pas avoir à déterminer les colonnes utiles au moment du calcul de L[:j].\n\n\n\n\n\n\nImportant\n\n\n\n\nIl y a un peu de manipulation pénible à faire sur les L[:i] pour en extraire la sous-partie utile au calcul de L[:j].\nOn ne peut jitter le code en l’état actuel\n\n\n\n\ndef _sparse_cholesky_csc_impl_modif(L_indices, L_indptr, L_x, row_useful):\n    n = len(L_indptr) - 1\n    # parcours sur colonnes\n    for j in range(0, n):\n        tmp = np.copy(L_x[L_indptr[j]:L_indptr[j + 1]]) # j-eme colonne de L, ie il ne faut pas de valeur manquante (même structure de sparsité\n        # dans 1ere col de L et de A (oui il suffit de voir l'algo e_tree pour j=0, on a un seul noeud dans cet e_tree)\n\n        # MAJ de la colonne courante avec le contenu de \n        for k in row_useful[j]: # voir eq slice 1/37\n            # if (k == row_useful[j][0]): \n            #     print(\"########## Looking at column\", j)\n            #     print(\"With non nul rows:\", L_indices[L_indptr[j]:L_indptr[j+1]])\n            #     print(\"Current value of column j:\", tmp)\n            # print(\"#### Looking at column\", k, \"to update column\", j)\n            # print(\"#### Value of column\", k, L_x[L_indptr[k]:L_indptr[k+1]])\n            ## row indices higher than j in column k which is required to update column j\n            col_k_ind = L_indices[L_indptr[k]:L_indptr[k+1]]\n            ## find element corresponding to row j in column k\n            pad = np.where(L_indices[L_indptr[k]:L_indptr[k+1]] == j)[0][0]\n            # print(L_indices[L_indptr[k]:L_indptr[k+1]], pad)\n\n            Ljk = L_x[L_indptr[k] + pad]\n            # print(\"Ljk =\", Ljk)\n            col_k_ind = L_indices[(L_indptr[k] + pad):L_indptr[k+1]]\n            update_idx = np.nonzero(np.isin(                                 \\\n              L_indices[L_indptr[j]:L_indptr[j+1]], col_k_ind                          \\\n              ))[0]\n            # print(\"row indices that should be updated using values from columun k:\", col_k_ind)\n            # print(\"row indices updated in column j:\", L_indices[L_indptr[j]:L_indptr[j+1]][update_idx])\n            ## Update only required elements\n            # print(col_k_ind)\n            # print(\"Update of column j:\", L_x[(L_indptr[k] + pad):L_indptr[k+1]]) \n            tmp[update_idx] = tmp[update_idx] - Ljk * L_x[(L_indptr[k] + pad):L_indptr[k+1]]\n            # print(\"Current value of column j:\", tmp)\n            \n            # pad = np.nonzero(                                                \\\n            #   L_indices[L_indptr[k]:L_indptr[k+1]] == L_indices[L_indptr[j]])[0][0]\n            # update_idx = np.nonzero(np.in1d(                                 \\\n            #   L_indices[L_indptr[j]:L_indptr[j+1]],                          \\\n            #   L_indices[(L_indptr[k] + pad):L_indptr[k+1]]))[0]\n            # tmp[update_idx] = tmp[update_idx] -                              \\\n            #   Ljk * L_x[(L_indptr[k] + pad):L_indptr[k + 1]]\n            \n        diag = np.sqrt(tmp[0])\n        L_x[L_indptr[j]] = diag\n        L_x[(L_indptr[j] + 1):L_indptr[j + 1]] = tmp[1:] / diag  # calcul de la j-eme col de L sauf diag.\n        # print(tmp[1:].shape, L_x[(L_indptr[j] + 1):L_indptr[j + 1]].shape)\n        # print(\"Final value of tmp:\", (tmp[1:] / diag))\n        # print(\"Final value of column j:\", L_x[(L_indptr[j] + 1):L_indptr[j + 1]])\n        # Pour le cas j=0 il nous faut bien\n        # que la struct de sparsité de A de la première col soit celle de L\n    return L_x\n\n\nL_x_recons = _sparse_cholesky_csc_impl_modif(L_indices, L_indptr, np.copy(L_x), row_useful)\n\n\nL_recons_csc = sparse.CSC((L_x_recons, L_indices, L_indptr), shape=(9,9))\nL_recons = L_recons_csc.todense()\nL_recons[:, 4]\n\nL_true = np.linalg.cholesky(A)\nL_true[:, 4]\n\nA_ = (L_recons @ L_recons.T)\nassert jnp.allclose(A_, A, atol=1e-7)\nprint(\"Victoire !!!!\")\n\nVictoire !!!!\n\n\nÀ la précision machine près, notre cholesky sparse donne le même résultat que celle de numpy 🥳."
  },
  {
    "objectID": "traccar.html",
    "href": "traccar.html",
    "title": "Traccar",
    "section": "",
    "text": "Traccar is an open-source GPS tracking platform. It allows you to track vehicles, people, or any GPS-enabled device in real time. It comes with a web User Interface to view devices on a map and can integrate a large number of GPS tracking devices.\nIt works with:\n\na GPS device (can be a smartphone) that sends location data to the Traccar server.\na server that stores data in a database (e.g., an OVH server).\na web app and APIs that allow you to visualize, analyze, or forward that data.\n\nWe first provide a tutorial to test the Traccar system (a demo provided by the developers). Then, we describe the main steps to build your own tracking system (setting up the server, connecting devices, and extracting the data from the database).\n\n\nFirst, download the Traccar client application and follow the installation steps.\n\n\n\n\n\nBy default, it should be connected to a demo server (http://demo.traccar.org) and have a specific device identifier.\nYou can connect to the server via this same link and add a system device (click the + symbol on the top of the left bar).\n\n\n\n\n\nTo connect your system device, you must enter your identifier in the Traccar client app in the identifier box.\n\n\n\n\n\nFrom the client app, send your location. This should now be visible on the Traccar Manager.\n⚠️ Note: There are several demo servers. If one server is not working properly (e.g., you cannot connect your device to it), try another one. Here is the list of demo servers.\nYou can follow your own track through time by clicking the replay button."
  },
  {
    "objectID": "traccar.html#demo-of-the-traccar-system",
    "href": "traccar.html#demo-of-the-traccar-system",
    "title": "Traccar",
    "section": "",
    "text": "First, download the Traccar client application and follow the installation steps.\n\n\n\n\n\nBy default, it should be connected to a demo server (http://demo.traccar.org) and have a specific device identifier.\nYou can connect to the server via this same link and add a system device (click the + symbol on the top of the left bar).\n\n\n\n\n\nTo connect your system device, you must enter your identifier in the Traccar client app in the identifier box.\n\n\n\n\n\nFrom the client app, send your location. This should now be visible on the Traccar Manager.\n⚠️ Note: There are several demo servers. If one server is not working properly (e.g., you cannot connect your device to it), try another one. Here is the list of demo servers.\nYou can follow your own track through time by clicking the replay button."
  },
  {
    "objectID": "traccar.html#setting-up-the-ovh-server",
    "href": "traccar.html#setting-up-the-ovh-server",
    "title": "Traccar",
    "section": "Setting up the OVH server",
    "text": "Setting up the OVH server\nFirst, subscribe to an OVH account for a Virtual Private Server (VPS). Choose an Ubuntu 24.04 distribution.\nIt is required to create an ssh authentification key. For the first login, you will need a temporary password, created for the first connection an send by email by OVH.\nAs Traccar relies on MySQL and we want to be able to administrate the MySQL Database, we first need to install the so-called LAMP stack:\n\nLinux\nApache\nMySQL\nphpMyAdmin\n\n\nStep 1: Install and configure Apache and MySQL\nsudo su -\napt update && apt upgrade -y && apt install apache2 -y\nsystemctl start apache2\nsystemctl enable apache2\n\napt install mysql-server -y\nsystemctl start mysql\nsystemctl enable mysql\n\nmysql_secure_installation\nChoose security level 1 (medium) and configure the root password.\nTypical configuration:\nPlease enter 0 = LOW, 1 = MEDIUM and 2 = STRONG: 1\nRemove anonymous users? (y|Y for Yes, any other key for No): y\nDisallow root login remotely? (y|Y for Yes, any other key for No): No\nRemove test database and access to it? (y|Y for Yes, any other key for No): n\nReload privilege tables now? (y|Y for Yes, any other key for No): y\nBy default, there is no root password. Let’s create one manually:\nmysql -u root\nALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY 'enter_your_root_password';\n\n\nStep 2: Install PHP and phpMyAdmin\nThis not mandatory for traccar but is helpful to explore the database.\napt install php libapache2-mod-php php-mysql php-mbstring php-zip php-gd php-json php-curl -y\napt install phpmyadmin -y\nDuring installation, choose: - Apache - Do not configure the phpmyadmin database automatically\n\n\nStep 3: Create the phpMyAdmin database and user\nmysql -u root -p\nCREATE DATABASE phpmyadmin;\nCREATE USER 'phpmyadmin'@'localhost' IDENTIFIED WITH mysql_native_password BY 'enter_phpmyadmin_password'; \nGRANT ALL PRIVILEGES ON phpmyadmin.* TO 'phpmyadmin'@'localhost';\nFLUSH PRIVILEGES;\nEXIT;\n\n\nImport phpMyAdmin tables\nmysql -u root -p phpmyadmin &lt; /usr/share/phpmyadmin/sql/create_tables.sql\n\n\nEdit the configuration file\nnano /etc/phpmyadmin/config-db.php\n&lt;?php\n$dbuser='phpmyadmin';\n$dbpass='enter_phpmyadmin_password';\n$basepath='';\n$dbname='phpmyadmin';\n$dbserver='localhost';\n$dbport='3306';\n$dbtype='mysql';\n?&gt;\nYou can now access phpMyAdmin at:\n👉 http://your-server-ip/phpmyadmin with your root or phpmyadmin credentials."
  },
  {
    "objectID": "traccar.html#installing-traccar",
    "href": "traccar.html#installing-traccar",
    "title": "Traccar",
    "section": "Installing Traccar",
    "text": "Installing Traccar\n\nStep 1: Prepare MySQL for Traccar\nThe Traccar installer temporarily uses root/root. We need to relax password restrictions:\nSET GLOBAL validate_password.LENGTH = 4;\nSET GLOBAL validate_password.policy = 0;\nSET GLOBAL validate_password.mixed_case_count = 0;\nSET GLOBAL validate_password.number_count = 0;\nSET GLOBAL validate_password.special_char_count = 0;\nSET GLOBAL validate_password.check_user_name = 0;\n\nALTER USER 'root'@'localhost' IDENTIFIED BY 'root';\nGRANT ALL ON *.* TO 'root'@'localhost' WITH GRANT OPTION;\n\nCREATE USER 'traccar'@'localhost' IDENTIFIED WITH mysql_native_password BY 'enter_traccar_password';\nCREATE DATABASE traccar;\nGRANT ALL PRIVILEGES ON traccar.* TO 'traccar'@'localhost';\nFLUSH PRIVILEGES;\nEXIT;\n\n\nStep 2: Install Traccar\nwget https://www.traccar.org/download/traccar-linux-64-latest.zip\napt install unzip\nunzip traccar-linux-*.zip\n./traccar.run\n\n\nStep 3: Configure Traccar\nnano /opt/traccar/conf/traccar.xml\n&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;!DOCTYPE properties SYSTEM 'http://java.sun.com/dtd/properties.dtd'&gt;\n&lt;properties&gt;\n    &lt;entry key='database.driver'&gt;com.mysql.cj.jdbc.Driver&lt;/entry&gt;\n    &lt;entry key='database.url'&gt;jdbc:mysql://localhost/traccar?zeroDateTimeBehavior=round&amp;serverTimezone=UTC&amp;allowPublicKeyRetrieval=true&amp;useSSL=false&amp;allowMultiQueries=true&amp;autoReconnect=true&amp;useUnicode=yes&amp;characterEncoding=UTF-8&amp;sessionVariables=sql_mode=''&lt;/entry&gt;\n    &lt;entry key='database.user'&gt;traccar&lt;/entry&gt;\n    &lt;entry key='database.password'&gt;enter_traccar_password&lt;/entry&gt;\n&lt;/properties&gt;\n\n\nStep 4: Secure MySQL and start Traccar\nALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY 'enter_your_root_password';\nGRANT ALL PRIVILEGES ON traccar.* TO 'traccar'@'localhost';\nFLUSH PRIVILEGES;\nEXIT;\nVerify connection:\nmysql -u root -p\nThen start Traccar:\nservice traccar start\nThis last step will fill the database (and creates the diferent tables for the first call)"
  },
  {
    "objectID": "traccar.html#securing-with-apache-and-ssl",
    "href": "traccar.html#securing-with-apache-and-ssl",
    "title": "Traccar",
    "section": "Securing with Apache and SSL",
    "text": "Securing with Apache and SSL\nCreate the configuration file:\nnano /etc/apache2/sites-available/traccar.conf\n&lt;VirtualHost *:80&gt;\n  ServerName your-domain-or-ip\n  Redirect / https://your-domain-or-ip\n&lt;/VirtualHost&gt;\n\n&lt;IfModule mod_ssl.c&gt;\n    &lt;VirtualHost _default_:443&gt;\n        ServerName your-domain-or-ip\n        ServerAdmin your_email@example.com\n\n        DocumentRoot /var/www/html\n\n        ProxyPass /api/socket ws://localhost:8082/api/socket\n        ProxyPassReverse /api/socket ws://localhost:8082/api/socket\n\n        ProxyPass / http://localhost:8082/\n        ProxyPassReverse / http://localhost:8082/\n\n        SSLEngine on\n        SSLCertificateFile /etc/ssl/certs/ssl-cert-snakeoil.pem\n        SSLCertificateKeyFile /etc/ssl/private/ssl-cert-snakeoil.key\n    &lt;/VirtualHost&gt;\n&lt;/IfModule&gt;\nInstall SSL and required modules:\nsudo apt-get install ssl-cert\nsudo a2enmod ssl proxy_http proxy_wstunnel rewrite\nsudo service apache2 restart\nEnable the site and generate a Let’s Encrypt certificate:\nsudo a2dissite 000-default\nsudo a2ensite traccar\nsudo service apache2 restart\nsudo apt install certbot python3-certbot-apache\nsudo certbot --apache\nThe server mysql is now ready and the database which will be used to record the position data is named traccar."
  },
  {
    "objectID": "traccar.html#setting-up-the-individual-device",
    "href": "traccar.html#setting-up-the-individual-device",
    "title": "Traccar",
    "section": "Setting up the individual device",
    "text": "Setting up the individual device\nThe traccar client is available on the Apple store and the Google store. Once downladed, there is a few step to set up the client\nEnter the server address http://51.91.58.42:5055,\nChoose Précision de la localisation : la plus éllevée\nIntervalle (secondes) 30\nThe user has to send the device id to the traccar administrator\nOn the traccar server, click on the + to add a device and enter the device id.\nThe traccar app records the position when the traacar app is on. The user click on Envoyer la position to send the recoded positions to the traccar database."
  },
  {
    "objectID": "traccar.html#accès-à-la-base-de-données-tracca",
    "href": "traccar.html#accès-à-la-base-de-données-tracca",
    "title": "Traccar",
    "section": "Accès à la base de données tracca",
    "text": "Accès à la base de données tracca\nTO access the traccar database, one ption which works is to first create a ssh tunnel which links local port 3307 to remote port 3306 on the server via\nssh -L 3307:localhost:3306 root@51.91.58.42\nThen you can access to the database via mysql or through the following R script\n\nlibrary(DBI)\nlibrary(RMySQL)\n\n\n# Connexion\ncon &lt;- dbConnect(RMySQL::MySQL(),\n                 host = \"127.0.0.1\",\n                 port = 3307,\n                 dbname = \"traccar\",\n                 username = \"user_db_name\",\n                 password = \"user_db_passwd\")\n\n# Exemples de requêtes\ndevices &lt;- dbGetQuery(con, \"SELECT * FROM tc_devices\")\npositions &lt;- dbGetQuery(con, \"SELECT * FROM tc_positions\")\n\n# Fermer connexion\ndbDisconnect(con)\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(lubridate)\nlibrary(sf)\n\nLinking to GEOS 3.12.1, GDAL 3.8.4, PROJ 9.4.0; sf_use_s2() is TRUE\n\npositions |&gt; select(id, deviceid, devicetime, latitude,longitude) |&gt; group_by(deviceid) |&gt; count()\n\n# A tibble: 3 × 2\n# Groups:   deviceid [3]\n  deviceid     n\n     &lt;int&gt; &lt;int&gt;\n1        1    62\n2        2  1216\n3        3     9\n\npositions |&gt; select(id, deviceid, devicetime, latitude,longitude) |&gt;  ggplot() +aes(x=longitude, y = latitude, col = as.factor(deviceid)) + geom_path() \n\n\n\n\n\n\n\npositions |&gt; \n  mutate(temps = ymd_hms(devicetime)) |&gt;  \n  group_by(deviceid) |&gt;\n  mutate(elapse_time = temps - lag(temps)) |&gt; \n  ggplot() + aes(x=as.factor(deviceid), y = elapse_time) + geom_point() \n\nDon't know how to automatically pick scale for object of type &lt;difftime&gt;.\nDefaulting to continuous.\n\n\nWarning: Removed 3 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "animint.html",
    "href": "animint.html",
    "title": "Animint 2",
    "section": "",
    "text": "We follow a simplified version of the tutorial given here: https://rcdata.nau.edu/genomic-ml/animint2-manual/Ch08-WorldBank-facets.html"
  },
  {
    "objectID": "animint.html#data-loading-and-formatting",
    "href": "animint.html#data-loading-and-formatting",
    "title": "Animint 2",
    "section": "Data loading and formatting",
    "text": "Data loading and formatting\n\ndata(WorldBank)\nWorldBank$Region &lt;- sub(\" (all income levels)\", \"\", WorldBank$region, fixed=TRUE)\n\n# Remove NAs\ndf &lt;- data.table(WorldBank)[!(is.na(life.expectancy) | is.na(fertility.rate))] \n\n# Display only the region south asia for ease of vizualization\ndf &lt;- df[df$region == \"South Asia\"]\nyears &lt;- unique(df[, .(year)])\n\nThe helper functions FACETS etc will be used to generate adequate facet grids.\n\nadd_facets &lt;- function(df, top, side){\n  data.frame(df,\n             top=factor(top, c(\"Fertility rate\", \"Years\")),\n             side=factor(side, c(\"Years\", \"Life expectancy\")))\n}\nfacet_right &lt;- function(df) add_facets(df, \"Years\", \"Life expectancy\")\nfacet_left  &lt;- function(df) add_facets(df, \"Fertility rate\", \"Life expectancy\")"
  },
  {
    "objectID": "animint.html#first-animint-plot-show-life-expectancy-for-each-country-over-time",
    "href": "animint.html#first-animint-plot-show-life-expectancy-for-each-country-over-time",
    "title": "Animint 2",
    "section": "First animint plot: show life expectancy for each country over time",
    "text": "First animint plot: show life expectancy for each country over time\n\nlife_expect_plot &lt;- ggplot()+\n                          geom_line(aes(year, life.expectancy,\n                                        group = country, colour = country),\n                                        clickSelects = \"country\", data = facet_right(df),\n                                        size = 4, alpha = 3/5)\nlife_expect_plot\n\n\n\n\n\n\n\n\nWith animint, the plot is shown in the “Viewer” panel and one can select which countries should be left in the plot.\n\nanimint(life_expect_plot)"
  },
  {
    "objectID": "animint.html#adding-a-bar-to-highlights-a-year",
    "href": "animint.html#adding-a-bar-to-highlights-a-year",
    "title": "Animint 2",
    "section": "Adding a bar to highlights a year",
    "text": "Adding a bar to highlights a year\nThe important parameter here is ‘clickSelects’.\n\n# facet_right(years) contains the unique years of the df and 2 columns for facet used later in the tutorial\nplot_with_bar &lt;- life_expect_plot +\n                 geom_tallrect(aes(xmin = year-1/2, xmax = year+1/2),\n                               clickSelects=\"year\", data = facet_right(years),\n                               alpha=1/2, show.legend = T)\nanimint(plot_with_bar)"
  },
  {
    "objectID": "animint.html#modify-the-vertical-cursor-text-display-to-show-the-average-life-expectancy",
    "href": "animint.html#modify-the-vertical-cursor-text-display-to-show-the-average-life-expectancy",
    "title": "Animint 2",
    "section": "Modify the vertical cursor text display to show the average life expectancy",
    "text": "Modify the vertical cursor text display to show the average life expectancy\nBy default, the text displayed at the current state of the bar is the current value of the bar. Use the ‘toolkit’ argument in aes() to change what is displayed.\n\nyears_df &lt;- df %&gt;% group_by(year) %&gt;% dplyr::summarise(mean_life_expectancy = mean(life.expectancy))\n\nplot_with_bar &lt;- life_expect_plot +\n                        geom_tallrect(aes(xmin=year-1/2, xmax=year+1/2,\n                                          tooltip = paste0(\"Mean life expectancy: \",\n                                                           round(mean_life_expectancy, 1))),\n                                          clickSelects=\"year\",\n                                      data = facet_right(years_df), alpha=1/2) \n\nanimint(plot_with_bar)"
  },
  {
    "objectID": "animint.html#add-points-to-get-exact-value-of-life-expectancy-for-each-country",
    "href": "animint.html#add-points-to-get-exact-value-of-life-expectancy-for-each-country",
    "title": "Animint 2",
    "section": "Add points to get exact value of life expectancy for each country",
    "text": "Add points to get exact value of life expectancy for each country\nLike the bar above, we use the ‘tooltip’ argument\n\nfull_plot &lt;- plot_with_bar +\n                    geom_point(aes(year, life.expectancy, color = country,\n                                   tooltip = paste0(country, \" - Life expectancy :\",\n                                                 round(life.expectancy, 1))),\n                                   showSelected = \"country\",\n                                   clickSelects = \"country\",\n                               size = 2,\n                               data = facet_right(df)) \nanimint(full_plot)"
  },
  {
    "objectID": "animint.html#let-us-add-a-second-facet",
    "href": "animint.html#let-us-add-a-second-facet",
    "title": "Animint 2",
    "section": "Let us add a second facet",
    "text": "Let us add a second facet\nIn this part, this is where the functions facet_right and facet_left are useful. These functions creates columns to order the axis. Like ggplot, the variable used for facet must be a factor.\n\n# First add the facet grid\nplot_right &lt;- full_plot + theme_bw() +\n                theme(panel.margin=grid::unit(0, \"lines\")) +\n                facet_grid(side ~ top, scales=\"free\") + xlab(\"\") + ylab(\"\") +\n                theme_animint(width=600)\n\nWhen adding the second plot, we use the ‘showSelected’ argument, the variable must correspond to the one used in the first plot with the argument ‘clickSelected’\n\n# Add the 2nd plot\nplot_both &lt;- plot_right +\n  geom_point(aes(fertility.rate, life.expectancy,\n                colour=country, size=population, key=country),\n            clickSelects=\"country\",\n            showSelected = \"year\",\n            data = facet_left(df)) +\n      scale_size_animint(pixel.range=c(2, 20), breaks=10^(9:5))\n\n\nanimint(plot_both)"
  },
  {
    "objectID": "animint.html#generating-a-us-map",
    "href": "animint.html#generating-a-us-map",
    "title": "Animint 2",
    "section": "Generating a US map",
    "text": "Generating a US map\nWe first generate an animint map of the US on which each state can be selected\n\nUSpolygons &lt;- map_data(\"state\") # Animint function to create a map, \"state\" is for US states\n\nmap = ggplot() + \n      theme_animint(width=750, height=500) +\n      geom_polygon(aes(x=long, y=lat, group=group, tooltip = region),\n                   clickSelects=\"region\",\n                   data=USpolygons, \n                   fill=\"#000000\",\n                   colour=\"white\", \n                   size=0.5, \n                  alpha=1)\nanimint(map)"
  },
  {
    "objectID": "animint.html#adding-the-tornadoes-segments",
    "href": "animint.html#adding-the-tornadoes-segments",
    "title": "Animint 2",
    "section": "Adding the tornadoes segments",
    "text": "Adding the tornadoes segments\nLet us add to the maps segments that give the tornadoes trajectory (segment from start point to end point). We also use the parameter ‘showSelected’ so the the map displays the tornado only for a specific year.\n\nseg.color &lt;- \"#55B1F7\"\ntornadoes_map &lt;- map + \n                 geom_segment(aes(x=startLong, y=startLat,\n                                 xend=endLong, yend=endLat),\n                              colour=seg.color, size = 1.2,\n                              showSelected=\"year\",\n                              data=UStornadoes) \nanimint(tornadoes_map)"
  },
  {
    "objectID": "animint.html#adding-the-tornadoes-points",
    "href": "animint.html#adding-the-tornadoes-points",
    "title": "Animint 2",
    "section": "Adding the tornadoes points",
    "text": "Adding the tornadoes points\nSuperposing tornadoes end point to tornadoes segments.\n\npt.color &lt;- \"#9999F9\"\ntornadoes_map &lt;- tornadoes_map +\n                  geom_point(aes(endLong, endLat),               \n                             colour=pt.color, \n                             showSelected=\"year\",\n                             data=UStornadoes,\n                             size=1)\nanimint(tornadoes_map)"
  },
  {
    "objectID": "animint.html#creating-histograms-with-the-number-of-tornadoes-per-state-year",
    "href": "animint.html#creating-histograms-with-the-number-of-tornadoes-per-state-year",
    "title": "Animint 2",
    "section": "Creating histograms with the number of tornadoes per (state, year)",
    "text": "Creating histograms with the number of tornadoes per (state, year)\n\nUStornadoCounts &lt;- ddply(UStornadoes, .(region, year), summarize, count=length(region))\n\nThe tornadoes histogram per (state, year). We use the parameter ‘showSelected’ = region so that it can be linked to the map later. Similarly for the argument ‘clickSelects’ = year, it corresponds to ‘showSelected’ in the map.\n\ntornadoes_hist &lt;- ggplot() + \n                  xlab(\"year\") +\n                  ylab(\"Number of tornadoes\") +\n                  geom_bar(aes(year, count),\n                          clickSelects=\"year\", \n                          showSelected=\"region\",\n                          data=UStornadoCounts, \n                          stat=\"identity\", \n                          color = \"black\",\n                          fill = \"#22212100\",\n                          alpha = 1,\n                          position=\"identity\")\nanimint(tornadoes_hist)\n\n\n\n\n\n\nAdding value on top of the bar when it is clicked.\n\ntornadoes_hist &lt;- tornadoes_hist +\n                   geom_text(aes(year, count + 5, label=count),\n                             showSelected=c(\"region\", \"year\"),\n                             data=UStornadoCounts, size=20)\nanimint(tornadoes_hist)"
  },
  {
    "objectID": "animint.html#combining-the-map-and-histogram",
    "href": "animint.html#combining-the-map-and-histogram",
    "title": "Animint 2",
    "section": "Combining the map and histogram",
    "text": "Combining the map and histogram\n\nanimint(tornadoes_map, tornadoes_hist)"
  },
  {
    "objectID": "animint.html#get-the-data-to-plot",
    "href": "animint.html#get-the-data-to-plot",
    "title": "Animint 2",
    "section": "Get the data to plot",
    "text": "Get the data to plot\nFirst, let us get the data and usefull functions\n\nfrance_temperature=rast(\"data/EOBS_FR31.nc\")\n\n\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:terra':\n\n    intersect, union\n\n\nThe following objects are masked from 'package:data.table':\n\n    hour, isoweek, mday, minute, month, quarter, second, wday, week,\n    yday, year\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\ndates = seq.Date(ymd(\"1985-01-01\"),ymd(\"2015-12-31\"),by='day')\ndates = dates[\n  -which((month(dates)==2 & day(dates)==29))]\nfrance_temperature = france_temperature[[1:length(dates)]]\n\ndatessummers = dates[(month(dates)%in%6:8) & ( year(dates) %in% c(2003,2015,1990,1999)) ]\nsummers =subset(france_temperature, month(time(france_temperature)) %in% c(6,7,8))\nsummers =subset(summers, year(time(summers)) %in% c(2003,2015,1990,1999))\n\nnames(summers)=datessummers\n\n## function to get quantile map ----\n\nget_qmap=function(raster,li_q){\n  n=length(li_q)\n  s = c()\n  for(i in 1:n){\n    q=li_q[i]\n    s &lt;-c(s,app(raster, fun=function(i){quantile(i,q,na.rm=T)}))\n    \n  }\n  s=rast(s)\n  names(s) = li_q\n  return(s)\n}\n## get quantile maps from observation 1985-2015-------\nqmaps = (get_qmap(summers,c(0.9,0.95,0.98,0.99)))\nplot(qmaps)\n\n\n\n\n\n\n\n\nThe different maps are quantiles of temperature for each pixels.\n\n## function to get percentage of area over quantiles ----\nget_area_over_qmaps=function(raster,qmaps){\n  #returns a time dataframe of % of area over the maps in qmaps\n  # n+1 columns with n the number of layers in qmaps, named after quantiles.\n  \n  ngrid = global((not.na(raster)),sum)\n  \n  depsummer =data.frame(t=time(raster))\n  for(i in 1:nlyr(qmaps)){\n    qmap = qmaps[[i]]\n    summersq = raster&gt;qmap\n    depsummer[,i+1]= global(summersq,sum,na.rm=T)/ngrid\n  }\n  names(depsummer)=c('t',names(qmaps))\n  return(depsummer)\n}\n\ndata=get_area_over_qmaps(summers,qmaps)\ndepsummer=data\nlongdep=gather(depsummer,quantile,percentage,-t)\nlongdep$year =year(longdep$t)\nlongdep$day_of_year=yday(longdep$t)\nhead(depsummer)\n\n           t 0.9 0.95 0.98 0.99\n1 1990-06-01   0    0    0    0\n2 1990-06-02   0    0    0    0\n3 1990-06-03   0    0    0    0\n4 1990-06-04   0    0    0    0\n5 1990-06-05   0    0    0    0\n6 1990-06-06   0    0    0    0\n\nhead(longdep)\n\n           t quantile percentage year day_of_year\n1 1990-06-01      0.9          0 1990         152\n2 1990-06-02      0.9          0 1990         153\n3 1990-06-03      0.9          0 1990         154\n4 1990-06-04      0.9          0 1990         155\n5 1990-06-05      0.9          0 1990         156\n6 1990-06-06      0.9          0 1990         157\n\n\nlongdep contains for each date t, each quantile, each year and day_of_year the percentage of location over their quantile."
  },
  {
    "objectID": "animint.html#objective-number-1-getting-percentage-fyear-with-colorquantile-selecting-only-chosen-year-and-highlighting-only-chosen-quantile.",
    "href": "animint.html#objective-number-1-getting-percentage-fyear-with-colorquantile-selecting-only-chosen-year-and-highlighting-only-chosen-quantile.",
    "title": "Animint 2",
    "section": "Objective number 1 : getting percentage = f(year) with color=quantile , selecting only chosen year and highlighting only chosen quantile.",
    "text": "Objective number 1 : getting percentage = f(year) with color=quantile , selecting only chosen year and highlighting only chosen quantile.\n\nlibrary(animint2)\n\ngobs &lt;- animint2::ggplot() +\n  animint2::geom_line(\n   animint2::aes(x=day_of_year, y= percentage,group = interaction(quantile,year),color=quantile), data = longdep\n  ) +\n  animint2::labs(title = \"some summers - proportion of FR map exceeding given quantile - observations\")\n\ngobs\n\n\n\n\n\n\n\n\nThis is not very pretty ! There is too much info at once. We want to only plot a given year, selected using showSelected=c( “year”). And also, why not choosing the quantiles to plot ?\n\nplot_QER &lt;- animint2::ggplot()+\n\n animint2::geom_line(animint2::aes(\n    day_of_year,percentage,group=quantile,color=quantile),\n    clickSelects=c(\"year\",\"quantile\"), #use selection to choose the year.\n     showSelected=c( \"year\"), #only show the selected year\n    data=(longdep), size=4, alpha=3/5)+\n  theme_bw()+\n  xlab(\"Day of year\")+\n  ylab(\"Percentage\")\n\nanimint(plot_QER)\n\n\n\n\n\n\nWe can add a rectangle, higlighting a selected day (will be useful later)\n\nplot_QER &lt;- animint2::ggplot()+\n  \n  # highlight the chosen year again\n  geom_tallrect(animint2::aes(\n    xmin=day_of_year-1/2, xmax=day_of_year+1/2),\n    clickSelects=\"day_of_year\",\n    data=(longdep), alpha=1/2)+\n  \n animint2::geom_line(animint2::aes(\n    day_of_year,percentage,group=quantile,color=quantile),\n    clickSelects=c(\"year\",\"quantile\"), #use selection to choose the year.\n     showSelected=c( \"year\"), #only show the selected year\n    data=(longdep), size=4, alpha=3/5)+\n  theme_bw()+\n  xlab(\"Day of year\")+\n  ylab(\"Percentage\")\n\nanimint(plot_QER)"
  },
  {
    "objectID": "animint.html#objective-2-plot-the-temperature-for-chosen-day-t-of-a-given-year",
    "href": "animint.html#objective-2-plot-the-temperature-for-chosen-day-t-of-a-given-year",
    "title": "Animint 2",
    "section": "Objective 2 : plot the temperature for chosen day t of a given year",
    "text": "Objective 2 : plot the temperature for chosen day t of a given year\n\n# --- palette and limits ---\npal &lt;- c(\"black\",\"#67001f\",'#d73027','#f46d43','#fdae61','#fee090',\n         '#ffffbf','#e0f3f8','#abd9e9','#74add1','#4575b4','#313695')\nmm &lt;- c(0,36)\n# be careful, this is heavy data\nsummers_small &lt;- terra::aggregate(summers, fact = 1, fun = mean)\n\nWarning: [aggregate] all values in argument 'fact' are 1, nothing to do\n\n# --- 1. Raster data prepared for ggplot/animint2 ---\n# Extract one value per cell per date -&gt; convert to data.frame\n# summers is a SpatRaster with layers named as dates\nmap_df &lt;- as.data.frame(summers_small, xy = TRUE, na.rm = FALSE)\nmap_df &lt;- tidyr::pivot_longer(map_df, -c(x,y),\n                              names_to = \"t\",\n                              values_to = \"temperature\")\nmap_df$t &lt;- as.Date(map_df$t)\nmap_df$year &lt;- lubridate::year(map_df$t)\nmap_df$day_of_year &lt;- lubridate::yday(map_df$t)\n\n# --- 2. Map plot (left) ---\nmap_plot &lt;- animint2::ggplot() +\n  animint2::geom_tile(animint2::aes(x, y, fill = temperature),\n            data = map_df,\n            showSelected = c(\"year\",\"day_of_year\"),colour=NA) +\n  animint2::ggtitle(\"Date t (selected)\")+\n  animint2::scale_fill_gradientn(colors = rev(pal),\n                       na.value = \"transparent\",\n                       limits = mm) +\n  animint2::coord_equal() +\n  animint2::labs(fill = \"temperature\")+theme_bw()\nanimint(map_plot)"
  },
  {
    "objectID": "animint.html#objective-3-plot-together-the-map-of-temperature-at-a-day-highlighting-that-day-on-my-first-plot",
    "href": "animint.html#objective-3-plot-together-the-map-of-temperature-at-a-day-highlighting-that-day-on-my-first-plot",
    "title": "Animint 2",
    "section": "Objective 3 : plot together the map of temperature at a day, highlighting that day on my first plot",
    "text": "Objective 3 : plot together the map of temperature at a day, highlighting that day on my first plot\nCan take a while, because the dataframe for plotting is large. We have used shared variables names, so selecting from (year,day_of_year) has the same meaning in both graphs.\n\nanimint2::animint(plot_QER,map_plot, first = list(year = c(2003), day_of_year = c(200)))"
  },
  {
    "objectID": "animint.html#objective-4-show-maps-at-different-time-steps-t-1-t-and-t1-to-show-temporal-evolution",
    "href": "animint.html#objective-4-show-maps-at-different-time-steps-t-1-t-and-t1-to-show-temporal-evolution",
    "title": "Animint 2",
    "section": "Objective 4 : Show maps at different time steps : t-1, t and t+1, to show temporal evolution",
    "text": "Objective 4 : Show maps at different time steps : t-1, t and t+1, to show temporal evolution\n\n# Map t-1\nmap_t_minus1 &lt;- animint2::ggplot() +\n  animint2::geom_tile(\n    animint2::aes(x, y, fill = temperature),\n    data = map_df %&gt;% mutate(day_of_year = day_of_year + 1),\n    showSelected = c(\"year\", \"day_of_year\"),\n    alpha = 0.4,\n    colour = NA\n  ) +\n  ggtitle(\"t-1\") +\n  animint2::scale_fill_gradientn(colors = rev(pal),\n                                na.value = \"transparent\",\n                                limits = mm) +\n  animint2::coord_equal() +\n  theme_bw()\n\n# Map t\nmap_t &lt;- animint2::ggplot() +\n  animint2::geom_tile(\n    animint2::aes(x, y, fill = temperature),\n    data = map_df,\n    showSelected = c(\"year\", \"day_of_year\"),\n    alpha = 1,\n    colour = NA\n  ) +\n  ggtitle(\"t\") +\n  animint2::scale_fill_gradientn(colors = rev(pal),\n                                na.value = \"transparent\",\n                                limits = mm) +\n  animint2::coord_equal() +\n  theme_bw()\n\n# Map t+1\nmap_t_plus1 &lt;- animint2::ggplot() +\n  animint2::geom_tile(\n    animint2::aes(x, y, fill = temperature),\n    data = map_df %&gt;% mutate(day_of_year = day_of_year - 1),\n    showSelected = c(\"year\", \"day_of_year\"),\n    alpha = 0.4,\n    colour = NA\n  ) +\n  ggtitle(\"t+1\") +\n  animint2::scale_fill_gradientn(colors = rev(pal),\n                                na.value = \"transparent\",\n                                limits = mm) +\n  animint2::coord_equal() +\n  theme_bw()\n\nanimint(map_t_minus1,map_t,map_t_plus1)"
  },
  {
    "objectID": "animint.html#final-objective",
    "href": "animint.html#final-objective",
    "title": "Animint 2",
    "section": "Final objective",
    "text": "Final objective\nPut everything togeteher I wanted a specific layout but nothing worked. It does not give an error, but does not work anyway…\n\nanimint2::animint(map_t_minus1,map_t,map_t_plus1,plot_QER, first = list(year = c(2003), day_of_year = c(200)),arrange = list(\n    top_row = c(\"map_t_minus1\", \"map_t\", \"map_t_plus1\"),  # top row\n    bottom_row   = \"plot_QER\"                               # bottom row\n  ))"
  },
  {
    "objectID": "animint.html#final-final-objective-add-facets-to-make-it-pretty",
    "href": "animint.html#final-final-objective-add-facets-to-make-it-pretty",
    "title": "Animint 2",
    "section": "Final Final Objective : add facets to make it pretty",
    "text": "Final Final Objective : add facets to make it pretty\nMany thanks to Blanche who did not let me leave the room with an ugly plot.\nHelper functions add_facets add a column to a dataframe, allowing us to make a facet name. We choose to only put a top name for the date.\n\nadd_facets &lt;- function(df, top){\n  data.frame(df,\n             top=factor(top, c(\"t-1\", \"t\", \"t+1\")))\n}\nfacet_left  &lt;- function(df) add_facets(df, \"t-1\")\nfacet_middle &lt;- function(df) add_facets(df, \"t\")\nfacet_right  &lt;- function(df) add_facets(df, \"t+1\")\n\n\n# Map t-1\nmap_t &lt;- animint2::ggplot() +\n  animint2::geom_tile(\n    animint2::aes(x, y, fill = temperature),\n    data = facet_left(map_df %&gt;% mutate(day_of_year = day_of_year + 1)),\n    showSelected = c(\"year\", \"day_of_year\"),\n    alpha = 0.4,\n    colour = NA\n  ) +\n  animint2::scale_fill_gradientn(colors = rev(pal),\n                                na.value = \"transparent\",\n                                limits = mm) +\n  animint2::coord_equal() +\n  theme_bw() +\n  \n  animint2::geom_tile(\n    animint2::aes(x, y, fill = temperature),\n    data = facet_middle(map_df),\n    showSelected = c(\"year\", \"day_of_year\"),\n    alpha = 1,\n    colour = NA\n  ) +\n  animint2::scale_fill_gradientn(colors = rev(pal),\n                                na.value = \"transparent\",\n                                limits = mm) +\n  animint2::coord_equal() +\n  theme_bw() +\n  animint2::geom_tile(\n    animint2::aes(x, y, fill = temperature),\n    data = facet_right(map_df %&gt;% mutate(day_of_year = day_of_year - 1)),\n    showSelected = c(\"year\", \"day_of_year\"),\n    alpha = 0.4,\n    colour = NA\n  ) +\n  animint2::scale_fill_gradientn(colors = rev(pal),\n                                na.value = \"transparent\",\n                                limits = mm) +\n  animint2::coord_equal() +\n  theme_bw()+\n  \n  facet_wrap(~top)\n\nScale for 'fill' is already present. Adding another scale for 'fill', which\nwill replace the existing scale.\nScale for 'fill' is already present. Adding another scale for 'fill', which\nwill replace the existing scale.\n\nmap_t\n\n\n\n\n\n\n\nanimint(map_t,plot_QER, first = list(year = c(2003), day_of_year = c(200)))"
  },
  {
    "objectID": "animint.html#option-1-in-rmd-and-qmd",
    "href": "animint.html#option-1-in-rmd-and-qmd",
    "title": "Animint 2",
    "section": "Option 1: in rmd and qmd",
    "text": "Option 1: in rmd and qmd\nOutput directory auto-generated, be careful use only one animint per named code chunk."
  },
  {
    "objectID": "animint.html#option-2-html",
    "href": "animint.html#option-2-html",
    "title": "Animint 2",
    "section": "Option 2: html",
    "text": "Option 2: html\n\nanimint2dir(animint(plot_both),\n            out.dir = \"myplot\", \n            open.browser = FALSE)\n\nThe plot can be viewed with index.html. If the web page is blank, configure your browser to allow execution of local JavaScript code, as explained on the FAQ."
  },
  {
    "objectID": "autodiff.html",
    "href": "autodiff.html",
    "title": "Tutoriel de différentiation automatique",
    "section": "",
    "text": "Note\n\n\n\nL’obectif de ce tutoriel est de montrer comment utiliser JAX et PyTorch pour calculer le JVP (Jacobian Vector Product) et le VJP (Vector Jacobian Product) d’une fonction qui n’est disponible dans les primitives fournies par JAX/Torch. Les deux cas d’usage envisagées sont:\n\nl’utilisation d’une fonction non différentiable pour lesquels on veut écrire une dérivée “non-standard” afin de pouvoir l’utiliser dans JAX/Torch\nl’utilisation d’une fonction donc une approximation analytique de la dérivée est disponible mais qui n’est pas implémentée dans JAX/Torch\nDans ce tutoriel, on considère une fonction jouet \\(f\\) qui dépend d’une entrée \\(x\\) et de paramètres \\(a, b\\).\n\\[\nf: (x, a, b) \\in \\mathbb{R}^p \\times \\mathbb{R}^p \\times \\mathbb{R} \\mapsto \\tanh(a^\\top x + b) \\in \\mathbb{R}\n\\]\nOn rappelle que \\(tanh'(x) = 1 - \\tanh^2(x)\\) et que \\[\n\\frac{\\partial f}{\\partial x} = a.(1 - \\tanh^2(a^\\top x + b)) \\qquad \\frac{\\partial d}{\\partial f} = x.(1 - \\tanh^2(a^\\top x + b)) \\qquad \\frac{\\partial f}{\\partial b} = (1 - \\tanh^2(a^\\top x + b))\n\\] ou en mode matriciel \\[\n\\nabla f(x, a, b) = \\left(\\frac{\\partial f}{\\partial x}, \\frac{\\partial f}{\\partial a}, \\frac{\\partial f}{\\partial b}\\right)^\\top\n\\]\nOn rappelle que la différentiation automatique fait appel à la chain-rule. Pour une fonction \\(g\\) à valeurs dans \\(\\mathbb{R}^p \\times \\mathbb{R}^p \\times \\mathbb{R}\\), et en notant \\(h = f \\circ g\\), on a \\[\n\\begin{align}\n\\nabla h(z) & = \\frac{\\partial (f \\circ g)(z)}{\\partial z} = \\nabla f(g(z))^\\top \\nabla g(z) \\\\\n            & = \\frac{\\partial (f \\circ g)(z)}{\\partial z} = \\frac{\\partial h(z)}{\\partial g(z)} \\frac{\\partial g(z)}{\\partial z}\n\\end{align}            \n\\]\nOn peut calculer \\(\\nabla h(z)\\) de deux façons:\nEn pratique il faut écrire jvp et vjp pour chaque fonction utilisée dans la composition."
  },
  {
    "objectID": "autodiff.html#en-utilisant-les-primitives-de-torch",
    "href": "autodiff.html#en-utilisant-les-primitives-de-torch",
    "title": "Tutoriel de différentiation automatique",
    "section": "En utilisant les primitives de torch",
    "text": "En utilisant les primitives de torch\n\nimport torch\nimport numpy as np\n\nOn definit notre fonction \\(f\\) en torch.\n\ndef f_torch(x, a, b):\n    return torch.tanh(torch.dot(x, a) + b)\n\nOn définit des valeurs pour lesquelles on sait calculer facilement le gradient.\n\nx = torch.tensor([2., 3.], requires_grad = True)\na = torch.ones(2, requires_grad = True)\nb = torch.tensor(-2., requires_grad = True)\n\nEt on calcule les dérivées partielles (avec la convention \\(\\partial f / \\partial x =\\) x.grad).\n\n## Définit y par rapport à x\ny = f_torch(x, a, b)\ny\n## Calcule et évalue le graphe de différentiation automatique de y par rapport à x \ny.backward()\n## Renvoie dy/dx\nx.grad, a.grad, b.grad\n\n(tensor([0.0099, 0.0099]), tensor([0.0197, 0.0296]), tensor(0.0099))\n\n\nOn peut être plus concis pour calculer notre gradient (ici par rapport à \\(x\\)) en définissant directement la fonction \\((x, a, b) \\mapsto \\frac{\\partial f}{\\partial x}(x, a, b)\\) dans df_torch_dx\n\n\n\n\n\n\nNote\n\n\n\nLe paramètre argnums=0 précise qu’on calcule la dérivée par rapport au premier argument de \\(f\\), en l’occurence \\(x\\).\n\n\n\ndf_torch_dx = torch.func.grad(f_torch, argnums=0)\n\nOn vérifie que les deux façons de faire donnent le même résultat.\n\nassert torch.allclose(df_torch_dx(x, a, b), x.grad)"
  },
  {
    "objectID": "autodiff.html#en-utilisant-notre-propre-fonction",
    "href": "autodiff.html#en-utilisant-notre-propre-fonction",
    "title": "Tutoriel de différentiation automatique",
    "section": "En utilisant notre propre fonction",
    "text": "En utilisant notre propre fonction\nLe code qui suit correspond à l’application des informations disponibles dans la documentation de torch sur notre fonction example. Un autre tutoriel intéressant est le suivant.\nOn doit définir 4 méthodes: - forward qui reçoit les entrées et calcule la sortie - setup_context qui stocke dans un objet ctx des tenseurs qui peuvent être réutilisés au moment du calcul de la dérivée (dans notre exemple, on a juste besoin de \\(x\\), \\(a\\) et \\(1 - \\tanh^2(a^\\top x + b)\\). - backward (ou vjp) qui reçoit le gradient calculé en aval et renvoie le gradient, pour faire de la différentiation automatique en mode reverse. - jvp qui reçoit une différentielle calculée en amont et la multiplie en amont avant de la renvoyer, pour faire de la différentiation automatique en mode forward.\n\nDéfinition de la fonction\n\nclass f_torch_manual(torch.autograd.Function):\n    \"\"\"\n    We can implement our own custom autograd Functions by subclassing\n    torch.autograd.Function and implementing the forward and backward passes\n    which operate on Tensors.\n    \"\"\"\n\n    @staticmethod\n    def forward(x, a, b):\n        \"\"\"\n        In the forward pass we receive a Tensor containing the input and return\n        a Tensor containing the output.\n        \"\"\"\n        output = torch.tanh(torch.dot(a, x) + b)\n        return output\n\n    @staticmethod\n    def setup_context(ctx, inputs, output):\n        \"\"\"\n        ctx is a context object that can be used\n        to stash information for backward computation. You can cache tensors for\n        use in the backward pass using the ``ctx.save_for_backward`` method. Other\n        objects can be stored directly as attributes on the ctx object, such as\n        ``ctx.my_object = my_object``.\n        \"\"\"\n        x, a, b = inputs\n        ## save output to cut computation time\n        scaling = 1. - output.pow(2) # tanh' = 1 - tanh^2\n        ctx.save_for_backward(x, a, scaling)\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        \"\"\"        \n        In the backward pass we receive a Tensor containing the gradient of the loss\n        with respect to the output, and we need to compute the gradient of the loss\n        with respect to the input.\n        It corresponds to a Vector Jacobian Product (vjp), used for reverse auto-differentiation\n        \"\"\"\n        x, a, scaling = ctx.saved_tensors\n        grad_x = grad_output * a * scaling\n        grad_a = grad_output * x * scaling\n        grad_b = grad_output * scaling\n        return grad_x, grad_a, grad_b # on doit calculer les grad par rapport à tous les arguments rajouter grad par rapport à a et b\n\n    @staticmethod\n    def jvp(x, a, b, tangents):\n        \"\"\"                \n        It corresponds to a Jacobian Vector Product (jvp), used for forward auto-differentiation\n        \"\"\"\n        ## Vector v of small perturbations\n        tx, ta, tb = tangents\n        ## Matrix (in this case vector) of first order gradient\n        result = torch.tanh(torch.dot(a, x) + b)\n        scaling = (1. - result.pow(2))\n        Jx = a * scaling\n        Ja = x * scaling\n        Jb = scaling\n        ## Return J(x, a, b)v\n        return torch.dot(Jx, tx) + torch.dot(Ja, ta) + Jb * tb\n\n\n\nVérification des dérivées\n\nEn mode reverseEn mode forward\n\n\n\n## Définit f\nf = f_torch_manual.apply\nz = f(x, a, b)\n## Calcule et évalue le graphe de différentiation automatique de y par rapport à x \n## Réinitialise les gradients à zéro avant tout calcul \nx.grad.zero_(), a.grad.zero_(), b.grad.zero_()\nz.backward()\n## Renvoie dy/dx\nx.grad, a.grad, b.grad\n\n(tensor([0.0099, 0.0099]), tensor([0.0197, 0.0296]), tensor(0.0099))\n\n\nOn vérifie qu’on obtient bien le même résultat qu’en laissant torch faire le calcul :party:.\nOn aurait aussi pu utiliser les opérateurs fonctionnels pour calculer la fonction dérivée (en utilisant le mode reverse)\n\nf_grad_rev = torch.func.jacrev(func=f, argnums=(0, 1, 2))\n\net vérifier que le résultat coincide avec le calcul fait à la main.\n\nassert all(torch.allclose(f_grad_rev(x, a, b)[i], (x.grad, a.grad, b.grad)[i]) for i in range(2))\n\n\n\nOn calcule la dérivée par rapport à la première coordonnée de \\(x\\)\n\ntangents = (torch.tensor([1., 0.]), torch.tensor([0., 0.]), torch.tensor(0.))\nf_torch_manual.jvp(x = x, a = a, b = b, tangents = tangents)\n\ntensor(0.0099, grad_fn=&lt;AddBackward0&gt;)\n\n\npuis par rapport à la deuxième coordonnée de \\(a\\)\n\ntangents = (torch.tensor([0., 0.]), torch.tensor([0., 1.]), torch.tensor(0.))\nf_torch_manual.jvp(x = x, a = a, b = b, tangents = tangents)\n\ntensor(0.0296, grad_fn=&lt;AddBackward0&gt;)\n\n\nEt on valide que les résultats obtenus coïncident avec ceux obtenus en mode reverse et directement en utilisant torch 😁\n\n\n\n\n\n\nAvertissement\n\n\n\n\n\nEn théorie, on pourrait utiliser les opérateurs fonctionnels pour calculer la fonction dérivée (en utilisant le mode forward)\n\nf_grad_fwd = torch.func.jacfwd(func=f, argnums=(0, 1, 2))\n\nmais il faut définir une méthode statique vmap et je n’ai pas compris comment faire 😢"
  },
  {
    "objectID": "autodiff.html#comparaison-des-temps-de-calculs",
    "href": "autodiff.html#comparaison-des-temps-de-calculs",
    "title": "Tutoriel de différentiation automatique",
    "section": "Comparaison des temps de calculs",
    "text": "Comparaison des temps de calculs\nOn compare ici les temps de calculs du calcul du gradient en mode forward, reverse pour la version qui utilise les primitives de torch et en mode reverse pour notre version.\n\ndim = 100\na = torch.tensor(np.arange(dim)/ (dim*10), requires_grad = True)\nb = torch.tensor(0.5, requires_grad = True)\nx = torch.tensor( (np.arange(dim) - 37) / (dim*10), requires_grad = True)\n\n\nf_torch_grad_rev = torch.func.jacrev(func=f_torch, argnums=(0, 1, 2))\n%timeit f_torch_grad_rev(x, a, b)\nf_torch_grad_fwd = torch.func.jacfwd(func=f_torch, argnums=(0, 1, 2))\n%timeit f_torch_grad_fwd(x, a, b)\n%timeit f_grad_rev(x, a, b)\n\n448 μs ± 3.35 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n522 μs ± 1.8 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n797 μs ± 6.81 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)"
  },
  {
    "objectID": "autodiff.html#impact-de-jit",
    "href": "autodiff.html#impact-de-jit",
    "title": "Tutoriel de différentiation automatique",
    "section": "Impact de JIT",
    "text": "Impact de JIT\nOn essaie de jitter nos fonctions pour vérifier si cela accélère le calcul des gradients.\nPlus d’info sur le JIT dans pytorch sont disponibles dans cette documentation.\n\nf_torch_grad_rev_jit = torch.jit.trace(f_torch_grad_rev, (x, a, b))\nf_torch_grad_fwd_jit = torch.jit.trace(f_torch_grad_fwd, (x, a, b))\n# f_grad_rev_jit = torch.jit.trace(f_grad_rev, (x, a, b))\n\n\n%timeit f_torch_grad_rev_jit(x, a, b)\n%timeit f_torch_grad_fwd_jit(x, a, b)\n# %timeit f_grad_rev_jit(x, a, b)\n\n59.5 μs ± 161 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n128 μs ± 316 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)"
  },
  {
    "objectID": "autodiff.html#dérivée-par-rapport-à-x",
    "href": "autodiff.html#dérivée-par-rapport-à-x",
    "title": "Tutoriel de différentiation automatique",
    "section": "Dérivée par rapport à \\(x\\)",
    "text": "Dérivée par rapport à \\(x\\)\n\nimport jax\nimport jax.numpy as jnp\nfrom jax import grad, jit\nfrom jax import random\n\n## On définit une dimension arbitraire pour nos inputs\ndim = 100\n\n## On initialise les paramètres et le vecteur d'input de la fonction\na = jnp.arange(dim)/ (dim*10)\nb = 0.5\nx = (jnp.arange(dim) - 37) / (dim*10)\n\n## On définit une fonction simple dont on connaît les gradients analytiques\ndef f(x, a, b):\n    return jnp.tanh(jnp.dot(a, x) + b)\n\n## On affiche la valeur de la fonction pour vérifier que tout est ok\nf(x, a, b) \n\nArray(0.56842977, dtype=float32)\n\n\n\nDérivée par rapport à \\(x\\)Dérivée par rapport à \\(a\\) et \\(b\\)\n\n\nDans un premier temps, on peut définir les gradients exacts de cette fonction à partir d’une formule analytique.\n\ndef df_dx(x, a, b):\n    return a * (1 - jnp.tanh(jnp.dot(a, x) + b) **2)\n\nPuis on définit les gradients via autograd et on vérifie que les résultats sont identiques.\n\n## jax.grad calcule la formule backward par défaut\ngrad_df_dx = jax.grad(lambda x: f(x, a, b), argnums=0) \n## On peut aussi calculer la formule forward via jax.jacfwd\nfwdgrad_df_dx = jax.jacfwd(lambda x: f(x, a, b), argnums=0) \n\n## On vérifie que les gradients retournent des valeurs identiques\nassert jnp.allclose(grad_df_dx(x), df_dx(x, a, b))\nassert jnp.allclose(grad_df_dx(x), fwdgrad_df_dx(x))\n\n## Si les assertions ne retournent pas d'erreur, les gradients sont corrects\nprint('All good, we are ready to go!')\n\nAll good, we are ready to go!\n\n\n\n\nOn définit également les gradients exacts par rapport aux paramètres \\(a\\) et \\(b\\) pour vérifier que l’on pourrait les optimiser dans un algorithme d’apprentissage.\n\ndef df_dab(x, a, b):\n    return x * (1 - jnp.tanh(jnp.dot(a, x) + b) **2), 1 - jnp.tanh(jnp.dot(a, x) + b) **2\n\nPuis on définit ces gradients via autograd et on vérifie que les résultats sont identiques.\n\n## jax.grad calcule la formule backward par défaut\ngrad_df_dab = jax.grad(lambda a_b: f(x, *a_b), argnums=0)\n## On peut aussi calculer la formule forward via jax.jacfwd\nfwdgrad_df_dab = jax.jacfwd(lambda a_b: f(x, *a_b), argnums=0)\n\n## On vérifie que les gradients retournent des valeurs identiques\nassert all(jnp.allclose(grad_df_dab((a,b))[i], df_dab(x, a, b)[i]) for i in range(2))\nassert all(jnp.allclose(grad_df_dab((a,b))[i], fwdgrad_df_dab((a,b))[i]) for i in range(2))\n\n## Si les assertions ne retournent pas d'erreur, les gradients sont corrects\nprint('All good, we are ready to go!')\n\nAll good, we are ready to go!\n\n\n\n\n\nNous avons donc bien vérifié que les gradients calculés avec JAX sont identiques aux gradients analytiques."
  },
  {
    "objectID": "autodiff.html#avec-vjp-et-jvp",
    "href": "autodiff.html#avec-vjp-et-jvp",
    "title": "Tutoriel de différentiation automatique",
    "section": "Avec VJP et JVP",
    "text": "Avec VJP et JVP\nDans les sections précédentes, jax.jacrev et jax.jacfwd utilisent, respectivement, les VJP et les JVP des opérations élémentaires de la fonction f. Dans certains cas, nous pouvons avoir besoin de définir nous-mêmes les VJP et JVP comme vu en introduction.\nNous allons alors définir les VJP et JVP pour f à l’aide de gradients que nous connaissons analytiquement. Les VJP et JVP des fonctions élémentaires sous-jacentes ne seront alors plus utilisés.\n\nJVPVJP\n\n\nLien vers la documentation de JAX\nUn JVP est capable de dévoiler une colonne de la jacobienne à la fois. Ce n’est pas adapté pour cette fonction dont la jacobienne est large. Une passe JVP ne peut dévoiler qu’une seule dérivée partielle : si l’on veut la dérivée par rapport à chaque dimension de \\(x\\), chaque dimension de \\(a\\) et \\(b\\), il nous faut faire \\(dim + dim + 1\\) fois des JVPs ce qui n’est pas du tout efficace. Nous l’avons vu dans la section précédente où en fait, jax.jacfwd doit en fait appeler tous ces JVPs (ce qui est fait de manière cachée à l’utilisateur).\nPour définir un custom_jvp en JAX, il faut attacher à f, une fonction f_jvp, qui prend deux entrées primals le point où l’on calcule le gradient et tangents le vecteur tangent (à voir aussi comme les gradients en amont du graphe que l’on parcourt en descendant). f_jvp retourne un tuple de deux vecteurs, f(primals) et le JVP df_dx @ tangents, où, bien sûr, df_dx contient l’expression analytique de la dérivée (c’est une matrice jacobienne mais elle n’est jamais stockée en mémoire car tout de suite réduite par le produit matriciel).\nNous avons vu que si tangents est un vecteur one-hot encoded nous dévoilons une colonne de la matrice jacobienne (celle où se situe le \\(1\\)). Dans l’exemple ci-dessous nous calculons de manière forward \\(\\frac{\\partial f}{\\partial x_0}\\).\n\n@jax.custom_jvp\ndef f(x, a, b):\n    return jnp.tanh(jnp.dot(a, x) + b)\n\n@f.defjvp\ndef f_jvp(primals, tangents):\n    x, a, b = primals\n    x_dot, a_dot, b_dot = tangents\n    primal_out = f(x, a, b)\n    return primal_out, (jnp.dot(df_dx(x, a, b), x_dot) +  jnp.dot((x * (1 - primal_out ** 2)), a_dot) + jnp.dot((1 - primal_out ** 2), b_dot))\n\nx0_tangents = jnp.zeros(dim)\nx0_tangents = x0_tangents.at[0].set(1)\n_, x_dot = jax.jvp(f, (x, a, b), (x0_tangents, jnp.zeros(dim), 0.))\n\nassert jnp.allclose(grad_df_dx(x)[0], x_dot)\n\nprint(\"All right!\")\n\nAll right!\n\n\nOn note que, s’il est défini, le custom_jvp sera utilisé par JAX, en mode forward et en mode backward. Notons aussi la syntaxe particulière émanant du fait que f prend trois arguments en entrée.\n\n\nLien vers la documentation de JAX\nUn VJP est capable de dévoiler une ligne de la jacobienne à la fois. Cela va donc nous permettre de calculer toute la matrice jacobienne de \\(f\\) en un seul appel à JVP car c’est une matrice à une seule ligne. Nous l’avons vu dans la section précédente où en fait, jax.jacrec doit en fait appeler tous ces VJPs (ce qui est fait de manière cachée à l’utilisateur).\nSi nous souhaitons explicitement définir le VJP, nous devons d’abord écrire une fonction qui décrit la passe forward. C’est ici f_fwd qui retourne f(primal) et des valeurs stockées pour le moment de la passe backward (à la manière de save_for_backward vu dans la section pytorch !). Il faut ici bien réfléchir à ce qui est nécessaire de stocker et ce qui est superflu, afin d’optimiser au mieux le code. Ici nous stockons f(x,a,b), x et a car ces valeurs sont réutilisées dans la passe backward où nous calculons \\(g. \\frac{\\partial \\mathrm{tanh}(f(x,a,b))}{\\partial x}\\), \\(g.\\frac{\\partial \\mathrm{tanh}(f(x,a,b))}{\\partial a}\\) et \\(g.\\frac{\\partial \\mathrm{tanh}(f(x,a,b))}{\\partial b}\\). Avec \\(g\\) le gradient provenant de l’aval du graphe pour calculer les VJPs (rappelons que nous les calculons de manière backward en remontant le graphe).\nNous comprenons à nouveau que si g est un vecteur one-hot encoded nous dévoilons une ligne de la matrice jacobienne (celle où se situe le \\(1\\)).\nNous devons également écrire une fonction f_bwd qui prend en argument les valeurs stockées dans la passe forward ainsi que g défini dans le paragraphe précédent. Ici g est scalaire f a valeurs dans \\(\\mathbb{R}\\). f_bwd retourne autant de sorties que f compte d’entrées.\n\n@jax.custom_vjp\ndef f(x, a, b):\n    return jnp.tanh(jnp.dot(a, x) + b)\n\ndef f_fwd(x, a, b):\n    primal_out = f(x, a, b)\n    return primal_out, (x, a, primal_out)\n\ndef f_bwd(res, g):\n    x, a, primal_out = res\n    return (a * (1 - primal_out **2) * g, x * (1 - primal_out **2) * g, (1 - primal_out **2) * g)\n\nf.defvjp(f_fwd, f_bwd)\n_, f_vjp = jax.vjp(f, x, a, b) # renvoie f(primal) et f_vjp qui est une fonction qui doit être évaluée en `g`\n\nassert jnp.allclose(grad_df_dx(x), f_vjp(1.)[0])\nassert all(jnp.allclose(grad_df_dab((a,b))[i], f_vjp(1.)[i + 1]) for i in range(2))\nprint(\"All right!\")\n\nAll right!\n\n\nNotons que la définition d’un custom_vjp redéfinit la fonction grad qui utilise donc aussi f_fwd. Ainsi, nous avons l’équivalence :\n\nassert jnp.allclose(f_vjp(1.)[0], jax.grad(f)(x, a, b))\nprint(\"All right!\")\n\nAll right!"
  },
  {
    "objectID": "autodiff.html#conclusion",
    "href": "autodiff.html#conclusion",
    "title": "Tutoriel de différentiation automatique",
    "section": "Conclusion",
    "text": "Conclusion"
  },
  {
    "objectID": "how_to_build_your_package.html",
    "href": "how_to_build_your_package.html",
    "title": "How To Build Your Package - Julia edition",
    "section": "",
    "text": "make a package available on GitHub - used in this work\nExample template for GitHub\nBest practices in Julia\nModules\nPkgTemplates.jl (is used in following )\nmake a package using PkgTemplates, then register it for the julia registry - way simpler !"
  },
  {
    "objectID": "how_to_build_your_package.html#defining-a-module",
    "href": "how_to_build_your_package.html#defining-a-module",
    "title": "How To Build Your Package - Julia edition",
    "section": "Defining a module",
    "text": "Defining a module\nFor large Julia packages, the code is usually organized in files, like\nmodule SomeModule\n# export, public, using, import statements are usually here; we discuss these below\ninclude(\"file1.jl\")\ninclude(\"file2.jl\")\nend"
  },
  {
    "objectID": "how_to_build_your_package.html#export-lists",
    "href": "how_to_build_your_package.html#export-lists",
    "title": "How To Build Your Package - Julia edition",
    "section": "Export lists",
    "text": "Export lists\nexport list = name of the different functions, types, global variables, constants… that are visible from the outside of the module when using it.\nmodule NiceStuff\n       export nice, DOG\n       struct Dog end      # singleton type, not exported\n       const DOG = Dog()   # named instance, exported\n       nice(x) = \"nice $x\" # function, exported\nend;\nmeans that when calling\n using .NiceStuff\nfunctions nice and constant DOG will be available under their names nice and DOG , but that Dog will be available through NiceStuff.Dog.\nFor example, it means that if we define helper functions used inside a fit_mle then we can keep them hidden in the package, and only export the final function !\nThere can be as many export as wanted, located anywhere in the module block, but it is recommended to put it at the beggining of the code."
  },
  {
    "objectID": "how_to_build_your_package.html#using-and-import-a-module",
    "href": "how_to_build_your_package.html#using-and-import-a-module",
    "title": "How To Build Your Package - Julia edition",
    "section": "using and import a module",
    "text": "using and import a module\nLoading from a package : using Module. Loading locally : using .Module\nimporting import .Module imports the module name, all of the objects must be named as NiceStuff.nice for example using the module name as a prefix. Or we can use import .Module: something to get the name something directly.\nTo modify a function (for example proposing a new class and extending a function to this new class ), there are two ways :\nCall the function by its entire name\nusing .NiceStuff\n\nstruct Cat end\n\nNiceStuff.nice(::Cat) = \"nice 😸\"\n@show(nice(Cat()))\nOr import it like this (this is where import is useful)\nimport .NiceStuff: nice\nnice(::Cat) = \"oo\"\n@show nice(Cat())\nWe can rename an import like this\nimport CSV as joli_csv"
  },
  {
    "objectID": "how_to_build_your_package.html#example-of-homemade-module",
    "href": "how_to_build_your_package.html#example-of-homemade-module",
    "title": "How To Build Your Package - Julia edition",
    "section": "Example of homemade module",
    "text": "Example of homemade module\nimport Pkg;\nPkg.add(\"Distributions\");\nPkg.add(\"ExtendedExtremes\");\nPkg.add(\"DocStringExtensions\");\n\n\n\n\n\n\nNote\n\n\n\nDocStringExtensions.jl exports a collection of macros, which can be used to add useful automatically generated information to docstrings.\n\n\n\nmodule MyExtendedExtremes\n\nexport MixedUniformTail, pdf, cdf, quantile, rand, fit_mix  #I export everything \n\nusing Distributions\nusing DocStringExtensions\nusing ExtendedExtremes\nusing Random \n\n\"\"\"\n$(TYPEDEF)\n\n$(TYPEDFIELDS)\n \nI wanted to put an uniform on the left part, an EGPD on the bulk and tail. \nEGPD only works when filtering very low value but I want all the values ! \n\"\"\"\nstruct MixedUniformTail{\n    T1&lt;:ContinuousUnivariateDistribution,\n    T2&lt;:ContinuousUnivariateDistribution,\n} &lt;: ContinuousUnivariateDistribution\n    \" probability of the left part \"\n    p::Float64\n    \" left part \"\n    uniform_part::T1\n    \" right part \"\n    tail_part::T2 \n    \" minimum value, for precip it is 0.1 \"\n    a::Float64 \n    \" threshold between both part, 0.5 for precips (included in left part) \"\n    b::Float64 \nend\n\nimport Distributions: pdf\n\n\"\"\"\n$(SIGNATURES)\n\nPDF\n\"\"\"\nfunction pdf(d::MixedUniformTail, y::Real)\n    if y &lt; d.a\n        return 0.0\n    elseif y &lt;= d.b\n        return d.p * pdf(d.uniform_part, y)\n    else\n        return (1 - d.p) * pdf(d.tail_part, y - d.b)\n    end\nend\n\nimport Distributions: cdf\n\n\"\"\"\n$(SIGNATURES)\n\nCDF\n\"\"\"\nfunction cdf(d::MixedUniformTail, y::Real)\n    if y &lt; d.a\n        return NaN\n    elseif y &lt;= d.b\n        return d.p * cdf(d.uniform_part, y)\n    else\n        return d.p + (1 - d.p) * cdf(d.tail_part, y - d.b)\n    end\nend\n\nimport Distributions: quantile\n\n\"\"\"\n$(SIGNATURES)\n\nQuantile function\n\"\"\"\nfunction quantile(d::MixedUniformTail, q::Real)\n    if q &lt; 0 || q &gt; 1\n        throw(DomainError(q, \"Quantile outside [0,1]\"))\n    end\n    if q &lt;= d.p\n        return quantile(d.uniform_part, q / d.p)\n    else\n        return d.b + quantile(d.tail_part, (q - d.p) / (1 - d.p))\n    end\nend\n\nimport Base: rand\n\nfunction rand(rng::AbstractRNG, d::MixedUniformTail)\n    if rand(rng) &lt;= d.p\n        return rand(rng, d.uniform_part)\n    else\n        return d.b + rand(rng, d.tail_part)\n    end\nend\n\nrand(d::MixedUniformTail) = rand(Random.GLOBAL_RNG, d)\n\n\"\"\"\n$(SIGNATURES)\n\nestimation\n\"\"\"\nfunction fit_mix(::Type{MixedUniformTail}, data; left = 0.1, middle = 0.5)\n    u = middle\n    prop_smallrain = sum(left .&lt;= data .&lt;= u) / sum(data .&gt; 0)\n    y = data[data .&gt; u] .- u\n\n    tail_part = fit_mle(ExtendedGeneralizedPareto{TBeta}, y)\n\n    return MixedUniformTail(prop_smallrain, Uniform(left, middle), tail_part, left, middle)\nend\n\nend\nNow, I have defined my module and I can use my new functions by using it:\nusing .MyModuleExtendedExtremes #it is a local module, so I have to use it like this\nusing Distributions\nusing ExtendedExtremes\nTry the new functions\n# Parameters\n\na, b = 0.1, 0.5\np = 0.3\n\n# Create the mixed distribution\n\nd = MixedUniformTail(p, Uniform(a, b), ExtendedGeneralizedPareto( TBeta(0.4), GeneralizedPareto(0.0,3, 0.1))   , a, b)\n\n# Example: use it like any Distributions.jl distribution\nprintln(pdf(d, 0.2))      # PDF in uniform part\nprintln(cdf(d, 0.2))      # CDF in uniform part\nprintln(quantile(d, 0.8)) # Quantile in tail part\n\n# Random draws\nsamples = rand(d, 10000)\n\nusing Plots\nhistogram(samples, bins=50, normalize=true, label=\"Sampled PDF\",alpha=0.3)\nplot!(x -&gt; pdf(d, x), 0, 50, label=\"Theoretical PDF\", lw=2)\n\n\ndd = fit_mix(MixedUniformTail,samples)\nsamples2=rand(dd,10000)\nhistogram!(samples2 , bins=50,normalize=true,label=\"samples from fitted on previous samples\",alpha=0.3)\nConclusion here : we have a module and some tests, now, how do we make that a proper package ?"
  },
  {
    "objectID": "how_to_build_your_package.html#creating-a-package",
    "href": "how_to_build_your_package.html#creating-a-package",
    "title": "How To Build Your Package - Julia edition",
    "section": "Creating a package",
    "text": "Creating a package\n\nCreate repository on GitHub. Custom : name it PackageName.jl\n\nFor me, MyExtendedExtremes.jl\n\ngenerate a basic package structure locally using generate\n\ncd to a folder where we want the package to be created. cd julia_package in my case\nstart Julia in this folder then in Julia REPL type ] generate PackageName (in my case ] generate MyExtendedExtremes)\n\n\n(@v1.11) pkg&gt; generate MyExtendedExtremes\n  Generating  project MyExtendedExtremes:\n    Project.toml\n    src/MyExtendedExtremes.jl\ngenerate has created the following files and folders :\nMyExtendedExtremes/\n├── Project.toml\n├── src/\n    └── MyExtendedExtremes.jl\nThe Project.toml contains for now only this :\nname = \"MyExtendedExtremes\"\nuuid = \"8f8ad11f-fafd-4bca-9428-2b36ffe65f47\"\nauthors = [\"cognot &lt;caroline.cognot@agroparistech.fr&gt;\"]\nversion = \"0.1.0\"\n\n\n\n\n\n\nNote\n\n\n\nTo develop your package, it is advisable to use Revise.jl. It may help you keep your Julia sessions running longer, reducing the need to restart when you make changes to code.\n\n\n\nactivate the package folder. In the same julia REPL : type ] activate Full/path/PackageName (in my case ]activate MyExtendedExtremes)\n\nResult in the REPL :\n(@v1.11) pkg&gt; activate MyExtendedExtremes\n  Activating project at `~/StateOfTheR/finistr2025/julia_package/MyExtendedExtremes`\nNow, the REPL when typing ] looks like this : (MyExtendedExtremes) pkg&gt;\n\nAdding the required packages : (in my case, it will be Distributions,ExtendedExtremes,Plots,Random) Activating has created an environment for the folder. This is when we can add packages dependencies, which will modify the Project.toml. (do not add unecessary packages). After adding the packages, now sections of the Project.toml have been created named [deps]and [compat].\nSpecify compatible functions in the [compat] section :\n\nadd julia = \"1.10.0\" for example (means, the package will work for versions of julia after 1.10.0)\nmodify if necessary the versions of the packages needed for compatibility.\n\n\nNow, it is the time to put all this on GitHub."
  },
  {
    "objectID": "how_to_build_your_package.html#link-the-package-to-github",
    "href": "how_to_build_your_package.html#link-the-package-to-github",
    "title": "How To Build Your Package - Julia edition",
    "section": "Link the package to GitHub",
    "text": "Link the package to GitHub\nWe can exit() julia.\nThe tutorial says to put this in git. First, go in the folder\ncd MyExtendedExtremes #I added this.\ngit init     # Initialise the git repository\ngit add .    # Add all files, including in subfolders\ngit commit -a -m \"Initial package structure of MyAwasomePackage\" # Create a first commit\ngit branch -m main # Rename \"master\" to \"main\" as of the new GitHub policy\ngit remote add origin git@github.com:caroline-cognot/MyExtendedExtremes.jl.git # Link the remote github repository to the local one\ngit config pull.rebase false # Allow mering of remote vs local codebase for next step\ngit pull origin main --allow-unrelated-histories # Fetch the Readme and gitignore we created when we created the repository\ngit push --set-upstream origin main # Finally upload everything back to the GitHub repository\nNow, the package exists : let us start julia, then we can add it by\nusing Pkg\nPkg.add(url=\"git@github.com:caroline-cognot/MyExtendedExtremes.jl.git\")\nNow I can import my package without the “.”\nusing MyExtendedExtremes \nBut there is no code inside yet. I have to add my module and make some tests.\nBy doing this, the package is moved in the julia dev directory :\n(@v1.11) pkg&gt; dev MyExtendedExtremes\nThe package and its code is now located inside this folder. We have to modify this folder instead of our previous folder (the old files are useless).\n(@v1.11) pkg&gt; dev /home/caroline/.julia/dev/MyExtendedExtremes"
  },
  {
    "objectID": "how_to_build_your_package.html#adding-functionalities-to-the-package",
    "href": "how_to_build_your_package.html#adding-functionalities-to-the-package",
    "title": "How To Build Your Package - Julia edition",
    "section": "Adding functionalities to the package",
    "text": "Adding functionalities to the package\nNow, I can edit my source by opening the file in VSCODE :\ncode /home/caroline/.julia/dev/MyExtendedExtremes/src/MyExtendedExtremes.jl\nAfter editing the file, restarting Julia then importing/using the package will make the functions available.\nusing MyExtendedExtremes\nusing Distributions,Random\nusing ExtendedExtremes\n######### try the new functions ###############################\"\n# Parameters\na, b = 0.1, 0.5\np = 0.3\n\n# Create the mixed distribution\nd = MixedUniformTail(p, Uniform(a, b), ExtendedGeneralizedPareto( TBeta(0.4), GeneralizedPareto(0.0,3, 0.1))   , a, b)"
  },
  {
    "objectID": "how_to_build_your_package.html#adding-tests",
    "href": "how_to_build_your_package.html#adding-tests",
    "title": "How To Build Your Package - Julia edition",
    "section": "Adding tests",
    "text": "Adding tests\ngo in the package directory, add a test/runtests.jl file and open it in vscode\ncd /home/caroline/.julia/dev/MyExtendedExtremes\nmkdir -p test \ncode test/runtests.jl\nNow, when I want to test the package, type\n] test MyExtendedExtremes"
  },
  {
    "objectID": "how_to_build_your_package.html#forgot-a-dependency",
    "href": "how_to_build_your_package.html#forgot-a-dependency",
    "title": "How To Build Your Package - Julia edition",
    "section": "Forgot a dependency ?",
    "text": "Forgot a dependency ?\n\ngo in the package folder\n\ncd /home/caroline/.julia/dev/MyExtendedExtremes\n\nstart julia\nactivate the package\n\nusing Pkg\nPkg.activate(\"/home/caroline/.julia/dev/MyExtendedExtremes\")\n\nadd the missing package\n\nPkg.add(\"Random\")\nIf it still does not work : in doubt kill all terminals and restart.\nor do it the way the tutorial says it in when adding the Test package :\n(@v1.x) pkg&gt; activate [USER_HOME_FOLDER]/.julia/dev/MyAwesomePackage/test/ #(remove test/ if the package has to be added in the package and not just in the test folder)\nadd Test\n(test) pkg&gt; activate # Without arguments, \"activate\" brings back to the default environment\n(@v1.x) pkg&gt; test MyAwesomePackage  # This perform the test"
  },
  {
    "objectID": "how_to_build_your_package.html#prepare-for-git-commit",
    "href": "how_to_build_your_package.html#prepare-for-git-commit",
    "title": "How To Build Your Package - Julia edition",
    "section": "Prepare for git commit",
    "text": "Prepare for git commit\nThe tutorial says to add a functionality that performs actions each time we git push by adding a file `[USER_HOME_FOLDER]/.julia/dev/MyExtendedExtremes/.github/workflows/ci.yml ̀\nThen it says to add badges on the readme .\nFrom a terminal in the right folder (~/.julia/dev/MyExtendedExtremes) I can now do\ngit commit -a -m \"Adding functions and testing\"\ngit push"
  },
  {
    "objectID": "how_to_build_your_package.html#it-is-here",
    "href": "how_to_build_your_package.html#it-is-here",
    "title": "How To Build Your Package - Julia edition",
    "section": "It is here !",
    "text": "It is here !\nhttps://github.com/caroline-cognot/MyExtendedExtremes.jl/"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "FinistR : bootcamp R à Roscoff",
    "section": "",
    "text": "L’atelier Finist’R 2025 – ou bootcamp R du groupe State Of The R se déroulera à la station biologique de Roscoff du 18 au 22 août 2025.\nStateoftheR est un réseau du département MathNum INRAE.\n\n\nIl s’agit de la neuvième édition de l’atelier Finist’R. Cet atelier réunit annuellement un groupe de chercheurs, ingénieurs, doctorants, tous utilisateurs avancés de R et développeurs de paquets pour explorer les dernières fonctionnalités du logiciel et les nouvelles pratiques de développement. A l’issue de l’atelier le collectif produit une synthèse de cette veille logiciel de manière à progresser collectivement dans l’utilisation du logiciel mais surtout dans la production d’outils statistiques à destination de la communauté.\nLe résultat de cette semaine est disponible sur cette page"
  },
  {
    "objectID": "index.html#où-quand",
    "href": "index.html#où-quand",
    "title": "FinistR : bootcamp R à Roscoff",
    "section": "",
    "text": "L’atelier Finist’R 2025 – ou bootcamp R du groupe State Of The R se déroulera à la station biologique de Roscoff du 18 au 22 août 2025.\nStateoftheR est un réseau du département MathNum INRAE.\n\n\nIl s’agit de la neuvième édition de l’atelier Finist’R. Cet atelier réunit annuellement un groupe de chercheurs, ingénieurs, doctorants, tous utilisateurs avancés de R et développeurs de paquets pour explorer les dernières fonctionnalités du logiciel et les nouvelles pratiques de développement. A l’issue de l’atelier le collectif produit une synthèse de cette veille logiciel de manière à progresser collectivement dans l’utilisation du logiciel mais surtout dans la production d’outils statistiques à destination de la communauté.\nLe résultat de cette semaine est disponible sur cette page"
  },
  {
    "objectID": "index.html#programme",
    "href": "index.html#programme",
    "title": "FinistR : bootcamp R à Roscoff",
    "section": "Programme",
    "text": "Programme"
  },
  {
    "objectID": "index.html#participants",
    "href": "index.html#participants",
    "title": "FinistR : bootcamp R à Roscoff",
    "section": "Participants",
    "text": "Participants\nBaptiste Alglave, Julie Aubert, Pierre Barbillon, Gloria Buritica, Lucia Clarotto, Caroline Cognot, Marie-Pierre Etienne, Armand Favrot, Blanche Francheterre, Hugo Gangloff, Pascal Irz, Louis Lacoste, Arthur Leroy, Mahendra Mariadassou, Pierre Navaro, Léo Micollet, Jeanne Tous."
  },
  {
    "objectID": "index.html#soutien",
    "href": "index.html#soutien",
    "title": "FinistR : bootcamp R à Roscoff",
    "section": "Soutien",
    "text": "Soutien"
  }
]